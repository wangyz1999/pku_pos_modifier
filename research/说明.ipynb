{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 不考虑词性，将分词形式有争议的词挑出\n",
    "为了达到这个目的，首先将分词剔除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'屹立 在 烟波 浩瀚 的 伶仃洋 上'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_pos(line):\n",
    "    if line[-1] == '\\n':\n",
    "        line = line[:-1]\n",
    "    if line[-1] == ' ':\n",
    "        line = line[:-1]\n",
    "    word_list = line.split(\" \")\n",
    "    out_line = \"\"\n",
    "    for i in range(len(word_list)):\n",
    "        try:\n",
    "            out_line += word_list[i][:word_list[i].index(\"/\")] + \" \"\n",
    "        except:\n",
    "            print(word_list)\n",
    "            print(i)\n",
    "            print(word_list[i-20:i])\n",
    "    out_line = out_line[:-1]\n",
    "    return out_line\n",
    "    \n",
    "remove_pos(\"屹立/v 在/p 烟波/n 浩瀚/v 的/u 伶仃洋/n 上/f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_ENCODING = \"utf-8-sig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下将分词不一样的两行挑出来，写入 seg_diff\n",
    "for i in range(1,138):\n",
    "    I_file = open(\"I_study\\\\study\" + str(i) + \".txt\", encoding=GLOBAL_ENCODING)\n",
    "    S_file = open(\"S_study\\\\study\" + str(i) + \".txt\", encoding=GLOBAL_ENCODING)\n",
    "\n",
    "    with open(\"seg_diff\\\\study\" + str(i) + \".txt\", 'w', encoding=GLOBAL_ENCODING) as diff:\n",
    "        while True:\n",
    "            I_line = I_file.readline()\n",
    "            S_line = S_file.readline()\n",
    "            if len(I_line) < 2 or len(S_line) < 2:\n",
    "                break\n",
    "#             try:\n",
    "            I_no_pos = remove_pos(I_line)\n",
    "            S_no_pos = remove_pos(S_line)\n",
    "#             except:\n",
    "#                 print(I_line)\n",
    "#                 print(\"\\n\")\n",
    "#                 print(S_line)\n",
    "#                 print(\"\\n\")\n",
    "#                 print(\"\\n\")\n",
    "\n",
    "            if I_no_pos != S_no_pos:\n",
    "                s = diff.write(I_no_pos)\n",
    "                s = diff.write('\\n')\n",
    "                s = diff.write(S_no_pos)\n",
    "                s = diff.write('\\n')\n",
    "                s = diff.write('\\n')\n",
    "\n",
    "    I_file.close()\n",
    "    S_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下将有分歧的词挑出来，写入word_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,138):\n",
    "    print(\"--------------------------------------\\n\"+str(i)+'\\n----------------------------\\n')\n",
    "    f = open(\"seg_diff\\\\study\" + str(i) + \".txt\", encoding=GLOBAL_ENCODING)\n",
    "    \n",
    "    with open(\"word_diff\\\\study\" + str(i) + \".txt\", 'w', encoding=GLOBAL_ENCODING) as wd:\n",
    "        while True:\n",
    "            I_line = f.readline()\n",
    "            if I_line == '':\n",
    "                break\n",
    "            S_line = f.readline()[:-1]\n",
    "            I_line = revised_line(I_line[:-1], S_line).split(\" \")\n",
    "            S_line = S_line.split(\" \")\n",
    "            e = f.readline()\n",
    "\n",
    "            i_idx = 0\n",
    "            s_idx = 0\n",
    "            i_str = \"\"\n",
    "            s_str = \"\"\n",
    "            w_i_str = \"\"\n",
    "            w_s_str = \"\"\n",
    "            while i_idx < len(I_line) and s_idx < len(S_line):\n",
    "                try:\n",
    "                    if I_line[i_idx] == S_line[s_idx]:\n",
    "                        g = nd.write(I_line[i_idx] + \" \")                     \n",
    "                    if i_str == s_str:\n",
    "                        if w_i_str != w_s_str:\n",
    "                            g = wd.write(\"<words>\" + i_str + '\\n')\n",
    "                            g = wd.write(\"<I_seg>\" + w_i_str + '\\n')\n",
    "                            g = wd.write(\"<S_seg>\" + w_s_str + '\\n')\n",
    "                            g = wd.write(\"\\n\")\n",
    "                            i_str = \"\"\n",
    "                            s_str = \"\"\n",
    "                            w_i_str = \"\"\n",
    "                            w_s_str = \"\"\n",
    "                            i_idx += 1\n",
    "                            s_idx += 1\n",
    "                        elif len(I_line[i_idx]) == len(S_line[s_idx]):\n",
    "                            i_idx += 1\n",
    "                            s_idx += 1\n",
    "                        else:\n",
    "                            i_str += I_line[i_idx]\n",
    "                            s_str += S_line[s_idx]\n",
    "                            w_i_str += I_line[i_idx]\n",
    "                            w_s_str += S_line[s_idx]\n",
    "                    elif len(i_str) > len(s_str):\n",
    "                        s_idx += 1\n",
    "                        s_str += S_line[s_idx]\n",
    "                        w_s_str += \" \" + S_line[s_idx]\n",
    "                    else:\n",
    "                        i_idx += 1\n",
    "                        i_str += I_line[i_idx]\n",
    "                        w_i_str += \" \" + I_line[i_idx]\n",
    "\n",
    "\n",
    "                except:\n",
    "#                     print(I_line)\n",
    "#                     print(S_line)\n",
    "#                     print(i_idx)\n",
    "#                     print(s_idx)\n",
    "#                     print(i_str + '\\n')\n",
    "#                     print(s_str + '\\n')\n",
    "#                     print(w_i_str + '\\n')\n",
    "#                     print(w_s_str + '\\n')\n",
    "    #                 sys.exit(0)\n",
    "                    break\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接下来针对有歧义的词进行全盘搜索\n",
    "\n",
    "### 参考stats.py\n",
    "### 注: stats.py 里有个mword.txt, 里面有一些统计结果，这个是曾经的一次错误统计（分词形式没错，但词性有错）因此第二次统计的时候直接用了这些词，这里直接当作是word_diff 中有分歧的那些词即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行完stats.py后会会得到许多小字典，将它们合成一个大字典,然后计算词频得到 “new_big_dict_ratio.txt”\n",
    "\n",
    "## stats.py的运行时间约为 8小时\n",
    "\n",
    "# -----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 首先将统计出的数据做成一个超大的字典\n",
    "* 这样以后可以直接读取json形式，或用python的eval()函数\n",
    "* 下面big_dict_ratio在统计频数的基础之上加了每个词占总出现次数的比值，以便之后进一步分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dict = dict()\n",
    "\n",
    "# with open(\"big_dict.txt\", 'w', encoding=\"utf-8-sig\") as bd:\n",
    "for i in range(1,17):\n",
    "    print(i)\n",
    "    f_name = \"big_dict_data\\\\\" + str(i) + \".txt\"\n",
    "    with open(f_name, encoding=\"utf-8-sig\") as fn:\n",
    "        while True:\n",
    "            l = fn.readline()\n",
    "            if len(l) == 0:\n",
    "                break\n",
    "            l = l[:-1]\n",
    "            pair = l.split(\"\\t\")\n",
    "            big_dict[pair[0]] = eval(pair[1])\n",
    "        # g = bd.write(str(big_dict))\n",
    "\n",
    "for key in big_dict:\n",
    "    times = big_dict[key]['a_time']\n",
    "    for i_seg in big_dict[key]['i_segs']:\n",
    "        i_frq = big_dict[key]['i_segs'][i_seg]['frq']\n",
    "        i_ratio = round(i_frq/times, 3)\n",
    "        big_dict[key]['i_segs'][i_seg]['rat'] = i_ratio\n",
    "    for s_seg in big_dict[key]['s_segs']:\n",
    "        s_frq = big_dict[key]['s_segs'][s_seg]['frq']\n",
    "        s_ratio = round(s_frq/times, 3)\n",
    "        big_dict[key]['s_segs'][s_seg]['rat'] = s_ratio\n",
    "\n",
    "with open(\"new_big_dict_ratio.txt\", 'w', encoding=\"utf-8-sig\") as bdr:\n",
    "    g = bdr.write(str(big_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接将数据读取成字典，方便以后使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dict = dict()\n",
    "with open(\"new_big_dict_ratio.txt\", encoding='utf-8-sig') as bdr:\n",
    "    big_dict = eval(bdr.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dict['王某']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ictclas 中的个别字在分词时会进行简繁转换，在此将其剔除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for k,v in list(big_dict.items()):\n",
    "    if len(v['i_segs']) == 0:\n",
    "        print(k)\n",
    "        del big_dict[k]\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 争议很大的情况 -- 写入 \"close.txt\" 文档\n",
    "* 对于某个词来说，如果两个分词器对其的所有分词形中，出现最多(比率之和大于0.9)的两种形式不相同\n",
    "* 则判定这个词对两个分词系统存在争议"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(\"close.txt\", 'w', encoding=\"utf-8-sig\") as cc:\n",
    "    for k in big_dict:\n",
    "\n",
    "        i_max_rat = max(big_dict[k]['i_segs'].values(), key=lambda x:x['rat'])['rat']\n",
    "        s_max_rat = max(big_dict[k]['s_segs'].values(), key=lambda x:x['rat'])['rat']\n",
    "\n",
    "        # 对于某个词来说，如果两个分词器对其的所有分词形中，出现最多(比率之和大于0.9)的两种形式不相同\n",
    "        # 则判定这个词对两个分词系统存在争议big\n",
    "        if i_max_rat + s_max_rat >= 0.9:\n",
    "            count += 1\n",
    "            word_dict = big_dict[k]\n",
    "            i_word = max(word_dict['i_segs'].items(), key=lambda x:x[1]['rat'])[0]\n",
    "            s_word = max(word_dict['s_segs'].items(), key=lambda x:x[1]['rat'])[0]\n",
    "            if i_word == s_word:\n",
    "                continue\n",
    "                \n",
    "            tmp_i_dic = dict()\n",
    "            tmp_s_dic = dict()\n",
    "            \n",
    "            for ipos in word_dict['i_segs']:\n",
    "                tmp_i_dic[ipos] = str(word_dict['i_segs'][ipos]['frq']) + \" (\" + str(word_dict['i_segs'][ipos]['rat']) + \")\" \n",
    "            for spos in word_dict['s_segs']:\n",
    "                tmp_s_dic[spos] = str(word_dict['s_segs'][spos]['frq']) + \" (\" + str(word_dict['s_segs'][spos]['rat']) + \")\"\n",
    "            \n",
    "            g = cc.write(k + \": \" + str(big_dict[k][\"a_time\"]) + '\\n')\n",
    "            g = cc.write(\"i_segs: \" + str(tmp_i_dic) + '\\n')\n",
    "            g = cc.write(\"s_segs: \" + str(tmp_s_dic) + '\\n')\n",
    "            g = cc.write(\"\\n\")\n",
    "print(\"共\" + str(count) + \"个词\") # 共13758个词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 针对模棱两可的情况 -- 写入 \"undecidable.txt\" 文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(\"undecidable.txt\", 'w', encoding=\"utf-8-sig\") as cc:\n",
    "    for k in big_dict:\n",
    "        i_max_rat = max(big_dict[k]['i_segs'].values(), key=lambda x:x['rat'])['rat']\n",
    "        s_max_rat = max(big_dict[k]['s_segs'].values(), key=lambda x:x['rat'])['rat']\n",
    "        if i_max_rat + s_max_rat < 0.65:\n",
    "            \n",
    "            word_dict = big_dict[k]\n",
    "            i_word = max(word_dict['i_segs'].items(), key=lambda x:x[1]['rat'])[0]\n",
    "            s_word = max(word_dict['s_segs'].items(), key=lambda x:x[1]['rat'])[0]\n",
    "            if i_word == s_word:\n",
    "                continue\n",
    "            count += 1\n",
    "            tmp_i_dic = dict()\n",
    "            tmp_s_dic = dict()\n",
    "            \n",
    "            for ipos in word_dict['i_segs']:\n",
    "                tmp_i_dic[ipos] = str(word_dict['i_segs'][ipos]['frq']) + \" (\" + str(word_dict['i_segs'][ipos]['rat']) + \")\" \n",
    "            for spos in word_dict['s_segs']:\n",
    "                tmp_s_dic[spos] = str(word_dict['s_segs'][spos]['frq']) + \" (\" + str(word_dict['s_segs'][spos]['rat']) + \")\"\n",
    "            \n",
    "            g = cc.write(k + \": \" + str(big_dict[k][\"a_time\"]) + '\\n')\n",
    "            g = cc.write(\"i_segs: \" + str(tmp_i_dic) + '\\n')\n",
    "            g = cc.write(\"s_segs: \" + str(tmp_s_dic) + '\\n')\n",
    "            g = cc.write(\"\\n\")\n",
    "print(\"共\" + str(count) + \"个词\") # 共120个词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 曹教授关于模棱两可的处理的四条建议：\n",
    "\n",
    "*** 建议之一\n",
    "\n",
    "先看两个例子：\n",
    "\n",
    "1. 将要有时是词，有时不是\n",
    "\n",
    "将要: 475\n",
    "i_segs: {'将 要': 178, '将要': 297}\n",
    "s_segs: {'将要': 314, '将 要': 161}\n",
    "\n",
    "2. 就是，同上\n",
    "\n",
    "就是: 47966\n",
    "i_segs: {'就 是': 34408, '就是': 13558}\n",
    "s_segs: {'就是': 27860, '就 是': 20106}\n",
    "\n",
    "因此，需要输出上述词的前后文，帮助判断。\n",
    "\n",
    "*** 建议之二\n",
    "\n",
    "代词+名词，则不合并。例如，\n",
    "\n",
    "此事: 1433\n",
    "i_segs: {'此事': 720, '此 事': 713}\n",
    "s_segs: {'此 事': 909, '此事': 524}\n",
    "\n",
    "*** 建议三\n",
    "百家姓+某\n",
    "老+百家姓\n",
    "小+百家姓\n",
    "则不合并。例如，\n",
    "\n",
    "谢 某\n",
    "周 某\n",
    "都是正确的分词。\n",
    "\n",
    "*** 建议四\n",
    "\n",
    "副词+动词\n",
    "副词+形容词\n",
    "副词+介词\n",
    "则不合并。例如，\n",
    "\n",
    "不知情: 226\n",
    "i_segs: {'不 知情': 76, '不知 情': 127, '不 知 情': 23}\n",
    "s_segs: {'不知情': 134, '不 知情': 92}\n",
    "\n",
    "不够: 3768\n",
    "i_segs: {'不 够': 2056, '不够': 1712}\n",
    "s_segs: {'不够': 2297, '不 够': 1471}\n",
    "\n",
    "竟/d 在/p\n",
    "是正确的分词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 针对四条处理建议:\n",
    "* 建议一的情况需要人工逐个考察，因此要首先处理，处理完成后将这些词从模棱两可的集合中去除，避免重复处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下代码中，第一个for循环自动生成建议二的config\n",
    "### 第二个for循环自动生成建议四的config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_only(item):\n",
    "    item_l = item.split(\" \")\n",
    "    item_str = \"\"\n",
    "    for il in item_l:\n",
    "        item_str += il[:il.index(\"/\")] + \" \"\n",
    "    return item_str[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(\"config_rule_undicibale.txt\", 'w', encoding=\"utf-8-sig\") as cu:\n",
    "    for k in big_dict:\n",
    "        i_max_rat = max(big_dict[k]['i_segs'].values(), key=lambda x:x['rat'])['rat']\n",
    "        s_max_rat = max(big_dict[k]['s_segs'].values(), key=lambda x:x['rat'])['rat']\n",
    "        if i_max_rat + s_max_rat < 0.65 and len(k) == 2:\n",
    "            i_dic = big_dict[k]['i_segs']\n",
    "            s_dic = big_dict[k]['s_segs']\n",
    "            \n",
    "            need_config = False\n",
    "            for segs in i_dic:\n",
    "                max_p = \"\"\n",
    "                p_num = 0\n",
    "                for pos in i_dic[segs]['pos']:\n",
    "                    if i_dic[segs]['pos'][pos] > p_num:\n",
    "                        max_p = pos\n",
    "                    \n",
    "                chars = max_p.split(\" \")\n",
    "                if len(chars) == 2 and '/r' in chars[0] and 'n' in chars[1]:\n",
    "                    need_config = True\n",
    "            for segs in s_dic:\n",
    "                max_p = \"\"\n",
    "                p_num = 0\n",
    "                for pos in s_dic[segs]['pos']:\n",
    "                    if s_dic[segs]['pos'][pos] > p_num:\n",
    "                        max_p = pos\n",
    "                    \n",
    "                chars = max_p.split(\" \")\n",
    "                if len(chars) == 2 and '/r' in chars[0] and 'n' in chars[1]:\n",
    "                    need_config = True\n",
    "            if need_config:\n",
    "                g = cu.write(\"//\" + k + \"\\n\")\n",
    "#                 g = cu.write(str(big_dict[k]) + '\\n')\n",
    "                correct_exp = k[0] + '/r' + ' ' + k[1] + '/n'\n",
    "                pos_set = set()\n",
    "                for segs in i_dic:\n",
    "                    for pos in i_dic[segs]['pos']:\n",
    "                        pos_set.add(pos)\n",
    "                for item in pos_set:\n",
    "                    if word_only(item) != word_only(correct_exp):\n",
    "                        g = cu.write('KEY' + item.replace(\" \", \"+\") + \"->[\" + item + \"]MERGE[\" + correct_exp + \"]\\n\")\n",
    "                g = cu.write(\"\\n\")\n",
    "    \n",
    "    for k in big_dict:\n",
    "        i_max_rat = max(big_dict[k]['i_segs'].values(), key=lambda x:x['rat'])['rat']\n",
    "        s_max_rat = max(big_dict[k]['s_segs'].values(), key=lambda x:x['rat'])['rat']\n",
    "        if i_max_rat + s_max_rat < 0.65 and len(k) == 2:\n",
    "            i_dic = big_dict[k]['i_segs']\n",
    "            s_dic = big_dict[k]['s_segs']\n",
    "            \n",
    "            need_config = False\n",
    "            correct_exp = \"\"\n",
    "            for segs in i_dic:\n",
    "                max_p = \"\"\n",
    "                p_num = 0\n",
    "                for pos in i_dic[segs]['pos']:\n",
    "                    if i_dic[segs]['pos'][pos] > p_num:\n",
    "                        max_p = pos\n",
    "                    \n",
    "                chars = max_p.split(\" \")\n",
    "                if len(chars) == 2 and '/d' in chars[0]:\n",
    "                    if '/v' in chars[1]:\n",
    "                        need_config = True\n",
    "                        correct_exp = k[0] + '/d' + ' ' + k[1] + '/v'\n",
    "                    if '/a' in chars[1]:\n",
    "                        need_config = True\n",
    "                        correct_exp = k[0] + '/d' + ' ' + k[1] + '/a'\n",
    "                    if 'p' in chars[1]:\n",
    "                        need_config = True\n",
    "                        correct_exp = k[0] + '/d' + ' ' + k[1] + '/p'\n",
    "                    \n",
    "            for segs in s_dic:\n",
    "                max_p = \"\"\n",
    "                p_num = 0\n",
    "                for pos in s_dic[segs]['pos']:\n",
    "                    if s_dic[segs]['pos'][pos] > p_num:\n",
    "                        max_p = pos\n",
    "                    \n",
    "                chars = max_p.split(\" \")\n",
    "                if len(chars) == 2 and '/d' in chars[0]:\n",
    "                    if '/v' in chars[1]:\n",
    "                        need_config = True\n",
    "                        correct_exp = k[0] + '/d' + ' ' + k[1] + '/v'\n",
    "                    if '/a' in chars[1]:\n",
    "                        need_config = True\n",
    "                        correct_exp = k[0] + '/d' + ' ' + k[1] + '/a'\n",
    "                    if 'p' in chars[1]:\n",
    "                        need_config = True\n",
    "                        correct_exp = k[0] + '/d' + ' ' + k[1] + '/p'\n",
    "                    \n",
    "            if need_config:\n",
    "                g = cu.write(\"// \" + k + \"\\n\")\n",
    "#                 g = cu.write(str(big_dict[k]) + '\\n')\n",
    "                pos_set = set()\n",
    "                for segs in i_dic:\n",
    "                    for pos in i_dic[segs]['pos']:\n",
    "                        pos_set.add(pos)\n",
    "                for item in pos_set:\n",
    "                    g = cu.write('KEY' + item.replace(\" \", \"+\") + \"->[\" + item + \"]MERGE[\" + correct_exp + \"]\\n\")\n",
    "                g = cu.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成config_confident 和 config_conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_w_any(seg):\n",
    "    l = seg.split(\" \")\n",
    "    s = \"\"\n",
    "    for w in l:\n",
    "        s += w + \"/ANY \"\n",
    "    return s[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_count = 0\n",
    "wd_count = 0\n",
    "_encoding = \"utf-8-sig\"\n",
    "\n",
    "nd = open(\"need_discuss_confident.txt\",'w',encoding=_encoding)\n",
    "wd = open(\"config_confident.txt\", 'w', encoding=_encoding)\n",
    "\n",
    "co = open(\"need_discuss_conflict.txt\", 'w', encoding=_encoding)\n",
    "co_count = 0\n",
    "co_dict = dict()\n",
    "\n",
    "cciu = open(\"config_conflict_I_u.txt\", 'w', encoding=_encoding)\n",
    "ccip = open(\"config_conflict_I_p.txt\", 'w', encoding=_encoding)\n",
    "ccif = open(\"config_conflict_I_f.txt\", 'w', encoding=_encoding)\n",
    "cciy = open(\"config_conflict_I_y.txt\", 'w', encoding=_encoding)\n",
    "ccim = open(\"config_conflict_I_m.txt\", 'w', encoding=_encoding)\n",
    "ccsu = open(\"config_conflict_S_u.txt\", 'w', encoding=_encoding)\n",
    "ccsp = open(\"config_conflict_S_p.txt\", 'w', encoding=_encoding)\n",
    "ccsf = open(\"config_conflict_S_f.txt\", 'w', encoding=_encoding)\n",
    "ccsy = open(\"config_conflict_S_y.txt\", 'w', encoding=_encoding)\n",
    "ccsm = open(\"config_conflict_S_m.txt\", 'w', encoding=_encoding)\n",
    "\n",
    "rn = open(\"config_r_n.txt\", 'w', encoding=_encoding)\n",
    "\n",
    "ad_v = open(\"config_adverb_v.txt\", 'w', encoding=_encoding)\n",
    "ad_a = open(\"config_adverb_a.txt\", 'w', encoding=_encoding)\n",
    "ad_p = open(\"config_adverb_p.txt\", 'w', encoding=_encoding)\n",
    "\n",
    "en = open(\"need_discuss_else.txt\", 'w', encoding=_encoding)\n",
    "en_dict = dict()\n",
    "\n",
    "cciu_count = 0\n",
    "ccip_count = 0\n",
    "ccif_count = 0\n",
    "cciy_count = 0\n",
    "ccim_count = 0\n",
    "ccsu_count = 0\n",
    "ccsp_count = 0\n",
    "ccsf_count = 0\n",
    "ccsy_count = 0\n",
    "ccsm_count = 0\n",
    "\n",
    "rn_count = 0\n",
    "\n",
    "ad_v_count = 0\n",
    "ad_a_count = 0\n",
    "ad_p_count = 0\n",
    "\n",
    "en_count = 0\n",
    "\n",
    "for item in big_dict:\n",
    "\n",
    "    word_dict = big_dict[item]\n",
    "    i_segs = big_dict[item][\"i_segs\"]\n",
    "    s_segs = big_dict[item][\"s_segs\"]\n",
    "\n",
    "    i_cons = dict()\n",
    "    s_cons = dict()\n",
    "\n",
    "    for i in i_segs:\n",
    "        i_cons[i] = i_segs[i]['rat']\n",
    "    for s in s_segs:\n",
    "        s_cons[s] = s_segs[s]['rat']\n",
    "        \n",
    "#     print(i_cons)\n",
    "#     print(s_cons)\n",
    "\n",
    "\n",
    "    i_con = max(i_cons.values())\n",
    "    s_con = max(s_cons.values())\n",
    "\n",
    "    if abs(i_con - s_con) >= 0.175:\n",
    "        correct_form = \"\"\n",
    "        if i_con > s_con:\n",
    "            correct_seg = max(i_cons, key=i_cons.get)\n",
    "            poss = i_segs[correct_seg]['pos']\n",
    "            check = sorted(poss.values())\n",
    "            if check[-1] / sum(check) < 0.8:\n",
    "                g = nd.write(item + \":\" + str(poss) + \"\\n\\n\")\n",
    "                nd_count += 1\n",
    "            else:\n",
    "                correct_form = max(poss, key=poss.get)\n",
    "        else:\n",
    "            correct_seg = max(s_cons, key=s_cons.get)\n",
    "            poss = s_segs[correct_seg]['pos']\n",
    "            check = sorted(poss.values())\n",
    "            if check[-1] / sum(check) < 0.8:\n",
    "                g = nd.write(item + \":\" + str(poss) + \"\\n\\n\")\n",
    "                nd_count += 1\n",
    "            else:\n",
    "                correct_form = max(poss, key=poss.get)\n",
    "\n",
    "#         KEY来自于/ANY->[来自于/ANY]MERGE[来自/v 于/p]\n",
    "        if correct_form != \"\":\n",
    "\n",
    "            correct_form = ict_pku(correct_form)\n",
    "\n",
    "            wd_count += 1\n",
    "            g = wd.write(\"// \" + item + '\\n')\n",
    "\n",
    "            seg_set = set()\n",
    "            for segs in i_cons:\n",
    "                seg_set.add(segs)\n",
    "            for segs in s_cons:\n",
    "                seg_set.add(segs)\n",
    "\n",
    "            for segs in seg_set:\n",
    "                if segs != correct_seg:\n",
    "                    g = wd.write(\"KEY\" + seg_w_any(segs).replace(\" \", \"+\") + \"->[\" + seg_w_any(segs) + \"]MERGE[\" + correct_form + \"]\\n\")\n",
    "            g = wd.write(\"\\n\")\n",
    "\n",
    "    # 争议很大\n",
    "    elif i_con + s_con >= 0.95:\n",
    "        i_rep_form = max(i_cons, key=i_cons.get)\n",
    "        s_rep_form = max(s_cons, key=s_cons.get)\n",
    "        if i_rep_form != s_rep_form:\n",
    "            if \" \" in i_rep_form and not \" \" in s_rep_form and i_rep_form.count(\" \") == 1:\n",
    "                poss = i_segs[i_rep_form]['pos']\n",
    "                check = sorted(poss.values())\n",
    "                if check[-1] / sum(check) < 0.8:\n",
    "                    co_dict[item] = big_dict[item]\n",
    "                    co_count += 1\n",
    "                else:\n",
    "                    correct_form = max(poss, key=poss.get)\n",
    "                    correct_form = ict_pku(correct_form)\n",
    "                    \n",
    "                    correct_form_str = \"\"\n",
    "                    correct_form_temp = correct_form.split(\" \")\n",
    "                    for cft in correct_form_temp:\n",
    "                        correct_form_str += cft[:cft.index(\"/\")] + \" \"\n",
    "                    correct_form_str = correct_form_str[:-1]\n",
    "                    \n",
    "                    if '/u' in correct_form:\n",
    "                        g = cciu.write(\"// \" + item + \"\\n\")\n",
    "                        cciu_count += 1\n",
    "                        all_segs = set()\n",
    "                        for k in i_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for k in s_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for ele in all_segs:\n",
    "                            if correct_form_str != ele:\n",
    "                                any_str_plus = ''.join(p+\"/ANY+\" for p in ele.split(\" \"))[:-1]\n",
    "                                any_str_space = any_str_plus.replace(\"+\", \" \")\n",
    "                                config_str = \"KEY\" + any_str_plus + \"->[\" + any_str_space + \"]MERGE[\" + correct_form + \"]\"\n",
    "                                g = cciu.write(config_str + \"\\n\")\n",
    "                            else:\n",
    "                                wl_seg = ele.split(\" \")\n",
    "                                corr_p = correct_form.split(\" \")\n",
    "                                corr_p1 = corr_p[0][corr_p[0].index(\"/\")+1:]\n",
    "                                corr_p2 = corr_p[1][corr_p[1].index(\"/\")+1:]\n",
    "                                g = cciu.write(\"KEY\" + wl_seg[0] + \"/ANY+\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p1 + '\\n')\n",
    "                                g = cciu.write(wl_seg[0] + \"/ANY+KEY\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p2 + '\\n')  \n",
    "                        g = cciu.write('\\n')\n",
    "                    elif '/p' in correct_form:\n",
    "                        g = ccip.write(\"// \" + item + \"\\n\")\n",
    "                        ccip_count += 1\n",
    "                        all_segs = set()\n",
    "                        for k in i_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for k in s_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for ele in all_segs:\n",
    "                            if correct_form_str != ele:\n",
    "                                any_str_plus = ''.join(p+\"/ANY+\" for p in ele.split(\" \"))[:-1]\n",
    "                                any_str_space = any_str_plus.replace(\"+\", \" \")\n",
    "                                config_str = \"KEY\" + any_str_plus + \"->[\" + any_str_space + \"]MERGE[\" + correct_form + \"]\"\n",
    "                                g = ccip.write(config_str + \"\\n\")\n",
    "                            else:\n",
    "                                wl_seg = ele.split(\" \")\n",
    "                                corr_p = correct_form.split(\" \")\n",
    "                                corr_p1 = corr_p[0][corr_p[0].index(\"/\")+1:]\n",
    "                                corr_p2 = corr_p[1][corr_p[1].index(\"/\")+1:]\n",
    "                                g = ccip.write(\"KEY\" + wl_seg[0] + \"/ANY+\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p1 + '\\n')\n",
    "                                g = ccip.write(wl_seg[0] + \"/ANY+KEY\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p2 + '\\n')  \n",
    "                        g = ccip.write('\\n')\n",
    "                    elif '/f' in correct_form:\n",
    "                        g = ccif.write(\"// \" + item + \"\\n\")\n",
    "                        ccif_count += 1\n",
    "                        all_segs = set()\n",
    "                        for k in i_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for k in s_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for ele in all_segs:\n",
    "                            if correct_form_str != ele:\n",
    "                                any_str_plus = ''.join(p+\"/ANY+\" for p in ele.split(\" \"))[:-1]\n",
    "                                any_str_space = any_str_plus.replace(\"+\", \" \")\n",
    "                                config_str = \"KEY\" + any_str_plus + \"->[\" + any_str_space + \"]MERGE[\" + correct_form + \"]\"\n",
    "                                g = ccif.write(config_str + \"\\n\")\n",
    "                            else:\n",
    "                                wl_seg = ele.split(\" \")\n",
    "                                corr_p = correct_form.split(\" \")\n",
    "                                corr_p1 = corr_p[0][corr_p[0].index(\"/\")+1:]\n",
    "                                corr_p2 = corr_p[1][corr_p[1].index(\"/\")+1:]\n",
    "                                g = ccif.write(\"KEY\" + wl_seg[0] + \"/ANY+\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p1 + '\\n')\n",
    "                                g = ccif.write(wl_seg[0] + \"/ANY+KEY\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p2 + '\\n')  \n",
    "                        g = ccif.write('\\n')\n",
    "                    elif '/y' in correct_form:\n",
    "                        g = cciy.write(\"// \" + item + \"\\n\")\n",
    "                        cciy_count += 1\n",
    "                        all_segs = set()\n",
    "                        for k in i_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for k in s_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for ele in all_segs:\n",
    "                            if correct_form_str != ele:\n",
    "                                any_str_plus = ''.join(p+\"/ANY+\" for p in ele.split(\" \"))[:-1]\n",
    "                                any_str_space = any_str_plus.replace(\"+\", \" \")\n",
    "                                config_str = \"KEY\" + any_str_plus + \"->[\" + any_str_space + \"]MERGE[\" + correct_form + \"]\"\n",
    "                                g = cciy.write(config_str + \"\\n\")\n",
    "                            else:\n",
    "                                wl_seg = ele.split(\" \")\n",
    "                                corr_p = correct_form.split(\" \")\n",
    "                                corr_p1 = corr_p[0][corr_p[0].index(\"/\")+1:]\n",
    "                                corr_p2 = corr_p[1][corr_p[1].index(\"/\")+1:]\n",
    "                                g = cciy.write(\"KEY\" + wl_seg[0] + \"/ANY+\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p1 + '\\n')\n",
    "                                g = cciy.write(wl_seg[0] + \"/ANY+KEY\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p2 + '\\n')  \n",
    "                        g = cciy.write('\\n')\n",
    "                    elif '/m' in correct_form:\n",
    "                        g = ccim.write(\"// \" + item + \"\\n\")\n",
    "                        ccim_count += 1\n",
    "                        all_segs = set()\n",
    "                        for k in i_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for k in s_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for ele in all_segs:\n",
    "                            if correct_form_str != ele:\n",
    "                                any_str_plus = ''.join(p+\"/ANY+\" for p in ele.split(\" \"))[:-1]\n",
    "                                any_str_space = any_str_plus.replace(\"+\", \" \")\n",
    "                                config_str = \"KEY\" + any_str_plus + \"->[\" + any_str_space + \"]MERGE[\" + correct_form + \"]\"\n",
    "                                g = ccim.write(config_str + \"\\n\")\n",
    "                            else:\n",
    "                                wl_seg = ele.split(\" \")\n",
    "                                corr_p = correct_form.split(\" \")\n",
    "                                corr_p1 = corr_p[0][corr_p[0].index(\"/\")+1:]\n",
    "                                corr_p2 = corr_p[1][corr_p[1].index(\"/\")+1:]\n",
    "                                g = ccim.write(\"KEY\" + wl_seg[0] + \"/ANY+\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p1 + '\\n')\n",
    "                                g = ccim.write(wl_seg[0] + \"/ANY+KEY\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p2 + '\\n')  \n",
    "                        g = ccim.write('\\n')\n",
    "                    else:\n",
    "                        co_dict[item] = big_dict[item]\n",
    "                        co_count += 1                \n",
    "                \n",
    "                           \n",
    "            elif \" \" in s_rep_form and not \" \" in i_rep_form and s_rep_form.count(\" \") == 1:\n",
    "                poss = s_segs[s_rep_form]['pos']\n",
    "                check = sorted(poss.values())\n",
    "                if check[-1] / sum(check) < 0.8:\n",
    "                    co_dict[item] = big_dict[item]\n",
    "                    co_count += 1\n",
    "                else:\n",
    "                    correct_form = max(poss, key=poss.get)\n",
    "                    correct_form = ict_pku(correct_form)\n",
    "                    \n",
    "                    correct_form_str = \"\"\n",
    "                    correct_form_temp = correct_form.split(\" \")\n",
    "                    for cft in correct_form_temp:\n",
    "                        correct_form_str += cft[:cft.index(\"/\")] + \" \"\n",
    "                    correct_form_str = correct_form_str[:-1]\n",
    "                    \n",
    "                    if '/u' in correct_form:\n",
    "                        g = ccsu.write(\"// \" + item + \"\\n\")\n",
    "                        ccsu_count += 1\n",
    "                        all_segs = set()\n",
    "                        for k in i_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for k in s_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for ele in all_segs:\n",
    "                            if correct_form_str != ele:\n",
    "                                any_str_plus = ''.join(p+\"/ANY+\" for p in ele.split(\" \"))[:-1]\n",
    "                                any_str_space = any_str_plus.replace(\"+\", \" \")\n",
    "                                config_str = \"KEY\" + any_str_plus + \"->[\" + any_str_space + \"]MERGE[\" + correct_form + \"]\"\n",
    "                                g = ccsu.write(config_str + \"\\n\")\n",
    "                            else:\n",
    "                                wl_seg = ele.split(\" \")\n",
    "                                corr_p = correct_form.split(\" \")\n",
    "                                corr_p1 = corr_p[0][corr_p[0].index(\"/\")+1:]\n",
    "                                corr_p2 = corr_p[1][corr_p[1].index(\"/\")+1:]\n",
    "                                g = ccsu.write(\"KEY\" + wl_seg[0] + \"/ANY+\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p1 + '\\n')\n",
    "                                g = ccsu.write(wl_seg[0] + \"/ANY+KEY\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p2 + '\\n')  \n",
    "                        g = ccsu.write('\\n')\n",
    "                    elif '/p' in correct_form:\n",
    "                        g = ccsp.write(\"// \" + item + \"\\n\")\n",
    "                        ccsp_count += 1\n",
    "                        all_segs = set()\n",
    "                        for k in i_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for k in s_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for ele in all_segs:\n",
    "                            if correct_form_str != ele:\n",
    "                                any_str_plus = ''.join(p+\"/ANY+\" for p in ele.split(\" \"))[:-1]\n",
    "                                any_str_space = any_str_plus.replace(\"+\", \" \")\n",
    "                                config_str = \"KEY\" + any_str_plus + \"->[\" + any_str_space + \"]MERGE[\" + correct_form + \"]\"\n",
    "                                g = ccsp.write(config_str + \"\\n\")\n",
    "                            else:\n",
    "                                wl_seg = ele.split(\" \")\n",
    "                                corr_p = correct_form.split(\" \")\n",
    "                                corr_p1 = corr_p[0][corr_p[0].index(\"/\")+1:]\n",
    "                                corr_p2 = corr_p[1][corr_p[1].index(\"/\")+1:]\n",
    "                                g = ccsp.write(\"KEY\" + wl_seg[0] + \"/ANY+\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p1 + '\\n')\n",
    "                                g = ccsp.write(wl_seg[0] + \"/ANY+KEY\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p2 + '\\n')  \n",
    "                        g = ccsp.write('\\n')\n",
    "                    elif '/f' in correct_form:\n",
    "                        g = ccsf.write(\"// \" + item + \"\\n\")\n",
    "                        ccsf_count += 1\n",
    "                        all_segs = set()\n",
    "                        for k in i_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for k in s_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for ele in all_segs:\n",
    "                            if correct_form_str != ele:\n",
    "                                any_str_plus = ''.join(p+\"/ANY+\" for p in ele.split(\" \"))[:-1]\n",
    "                                any_str_space = any_str_plus.replace(\"+\", \" \")\n",
    "                                config_str = \"KEY\" + any_str_plus + \"->[\" + any_str_space + \"]MERGE[\" + correct_form + \"]\"\n",
    "                                g = ccsf.write(config_str + \"\\n\")\n",
    "                            else:\n",
    "                                wl_seg = ele.split(\" \")\n",
    "                                corr_p = correct_form.split(\" \")\n",
    "                                corr_p1 = corr_p[0][corr_p[0].index(\"/\")+1:]\n",
    "                                corr_p2 = corr_p[1][corr_p[1].index(\"/\")+1:]\n",
    "                                g = ccsf.write(\"KEY\" + wl_seg[0] + \"/ANY+\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p1 + '\\n')\n",
    "                                g = ccsf.write(wl_seg[0] + \"/ANY+KEY\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p2 + '\\n')  \n",
    "                        g = ccsf.write('\\n')\n",
    "                    elif '/y' in correct_form:\n",
    "                        g = ccsy.write(\"// \" + item + \"\\n\")\n",
    "                        ccsy_count += 1\n",
    "                        all_segs = set()\n",
    "                        for k in i_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for k in s_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for ele in all_segs:\n",
    "                            if correct_form_str != ele:\n",
    "                                any_str_plus = ''.join(p+\"/ANY+\" for p in ele.split(\" \"))[:-1]\n",
    "                                any_str_space = any_str_plus.replace(\"+\", \" \")\n",
    "                                config_str = \"KEY\" + any_str_plus + \"->[\" + any_str_space + \"]MERGE[\" + correct_form + \"]\"\n",
    "                                g = ccsy.write(config_str + \"\\n\")\n",
    "                            else:\n",
    "                                wl_seg = ele.split(\" \")\n",
    "                                corr_p = correct_form.split(\" \")\n",
    "                                corr_p1 = corr_p[0][corr_p[0].index(\"/\")+1:]\n",
    "                                corr_p2 = corr_p[1][corr_p[1].index(\"/\")+1:]\n",
    "                                g = ccsy.write(\"KEY\" + wl_seg[0] + \"/ANY+\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p1 + '\\n')\n",
    "                                g = ccsy.write(wl_seg[0] + \"/ANY+KEY\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p2 + '\\n')  \n",
    "                        g = ccsy.write('\\n')\n",
    "                    elif '/m' in correct_form:\n",
    "                        g = ccsm.write(\"// \" + item + \"\\n\")\n",
    "                        ccsm_count += 1\n",
    "                        all_segs = set()\n",
    "                        for k in i_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for k in s_cons:\n",
    "                            all_segs.add(k)\n",
    "                        for ele in all_segs:\n",
    "                            if correct_form_str != ele:\n",
    "                                any_str_plus = ''.join(p+\"/ANY+\" for p in ele.split(\" \"))[:-1]\n",
    "                                any_str_space = any_str_plus.replace(\"+\", \" \")\n",
    "                                config_str = \"KEY\" + any_str_plus + \"->[\" + any_str_space + \"]MERGE[\" + correct_form + \"]\"\n",
    "                                g = ccsm.write(config_str + \"\\n\")\n",
    "                            else:\n",
    "                                wl_seg = ele.split(\" \")\n",
    "                                corr_p = correct_form.split(\" \")\n",
    "                                corr_p1 = corr_p[0][corr_p[0].index(\"/\")+1:]\n",
    "                                corr_p2 = corr_p[1][corr_p[1].index(\"/\")+1:]\n",
    "                                g = ccsm.write(\"KEY\" + wl_seg[0] + \"/ANY+\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p1 + '\\n')\n",
    "                                g = ccsm.write(wl_seg[0] + \"/ANY+KEY\" + wl_seg[1] + \"/ANY->ANY>>\" + corr_p2 + '\\n')  \n",
    "                        g = ccsm.write('\\n')\n",
    "                    else:\n",
    "                        co_dict[item] = big_dict[item]\n",
    "                        co_count += 1\n",
    "            else:\n",
    "                co_dict[item] = big_dict[item]\n",
    "                co_count += 1\n",
    "#   模棱两可            \n",
    "    else:\n",
    "        pass\n",
    "#     elif i_con + s_con < 0.65\n",
    "#         i_dic = i_segs\n",
    "#         s_dic = s_segs\n",
    "\n",
    "#         need_config = False\n",
    "#         for segs in i_dic:\n",
    "#             max_p = \"\"\n",
    "#             p_num = 0\n",
    "#             for pos in i_dic[segs]['pos']:\n",
    "#                 if i_dic[segs]['pos'][pos] > p_num:\n",
    "#                     max_p = pos\n",
    "\n",
    "#             chars = max_p.split(\" \")\n",
    "#             if len(chars) == 2 and '/r' in chars[0] and 'n' in chars[1]:\n",
    "#                 need_config = True\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "#         for segs in s_dic:\n",
    "#             max_p = \"\"\n",
    "#             p_num = 0\n",
    "#             for pos in s_dic[segs]['pos']:\n",
    "#                 if s_dic[segs]['pos'][pos] > p_num:\n",
    "#                     max_p = pos\n",
    "\n",
    "#             chars = max_p.split(\" \")\n",
    "#             if len(chars) == 2 and '/r' in chars[0] and 'n' in chars[1]:\n",
    "#                 need_config = True\n",
    "#         if need_config:\n",
    "#             g = cu.write(k + \"\\n\")\n",
    "#             g = cu.write(str(big_dict[k]) + '\\n')\n",
    "#             correct_exp = k[0] + '/r' + ' ' + k[1] + '/n'\n",
    "#             pos_set = set()\n",
    "#             for segs in i_dic:\n",
    "#                 for pos in i_dic[segs]['pos']:\n",
    "#                     pos_set.add(pos)\n",
    "#             for item in pos_set:\n",
    "#                 g = cu.write('KEY' + item.replace(\" \", \"+\") + \"->[\" + item + \"]MERGE[\" + correct_exp + \"]\\n\")\n",
    "#             g = cu.write(\"\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#         i_rep_form = max(i_cons, key=i_cons.get)\n",
    "#         s_rep_form = max(s_cons, key=s_cons.get)\n",
    "#         if \" \" in i_rep_form or not \" \" in s_rep_form and i_rep_form.count(\" \") == 1:\n",
    "#                 poss = i_segs[i_rep_form]['pos']\n",
    "#                 check = sorted(poss.values())\n",
    "#                 if check[-1] / sum(check) < 0.8:\n",
    "#                     co_dict[item] = big_dict[item]\n",
    "#                     co_count += 1\n",
    "#                 else:\n",
    "#                     correct_form = max(poss, key=poss.get)\n",
    "#                     correct_form = ict_pku(correct_form)\n",
    "                    \n",
    "#                     correct_form_str = \"\"\n",
    "#                     correct_form_temp = correct_form.split(\" \")\n",
    "#                     for cft in correct_form_temp:\n",
    "#                         correct_form_str += cft[:cft.index(\"/\")] + \" \"\n",
    "#                     correct_form_str = correct_form_str[:-1]\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if '/r' in correct_form.split(\" \")[0] and 'n' in correct_form.split(\" \")[0]:\n",
    "#             g = rn.write(\"// \" + item + \"\\n\")\n",
    "#             rn_count += 1\n",
    "#             all_segs = set()\n",
    "#             for k in i_cons:\n",
    "#                 all_segs.add(k)\n",
    "#             for k in s_cons:\n",
    "#                 all_segs.add(k)\n",
    "#             for ele in all_segs:\n",
    "#                 if correct_form_str != ele:\n",
    "#                     any_str_plus = ''.join(p+\"/ANY+\" for p in ele.split(\" \"))[:-1]\n",
    "#                     any_str_space = any_str_plus.replace(\"+\", \" \")\n",
    "#                     config_str = \"KEY\" + any_str_plus + \"->[\" + any_str_space + \"]MERGE[\" + correct_form + \"]\"\n",
    "#                     g = rn.write(config_str + \"\\n\")\n",
    "#         elif '/d' in correct_form.split(\" \")[0] and '/v' in correct_form.split(\" \")[0]:\n",
    "#             g = ad_v.write(\"// \" + item + \"\\n\")\n",
    "#             ad_v_count += 1\n",
    "#             all_segs = set()\n",
    "#             for k in i_cons:\n",
    "#                 all_segs.add(k)\n",
    "#             for k in s_cons:\n",
    "#                 all_segs.add(k)\n",
    "#             for ele in all_segs:\n",
    "#                 if correct_form_str != ele:\n",
    "#                     any_str_plus = ''.join(p+\"/ANY+\" for p in ele.split(\" \"))[:-1]\n",
    "#                     any_str_space = any_str_plus.replace(\"+\", \" \")\n",
    "#                     config_str = \"KEY\" + any_str_plus + \"->[\" + any_str_space + \"]MERGE[\" + correct_form + \"]\"\n",
    "#                     g = ad_v.write(config_str + \"\\n\")\n",
    "#         elif '/d' in correct_form.split(\" \")[0] and '/a' in correct_form.split(\" \")[0]:\n",
    "#             g = ad_a.write(\"// \" + item + \"\\n\")\n",
    "#             ad_a_count += 1\n",
    "#             all_segs = set()\n",
    "#             for k in i_cons:\n",
    "#                 all_segs.add(k)\n",
    "#             for k in s_cons:\n",
    "#                 all_segs.add(k)\n",
    "#             for ele in all_segs:\n",
    "#                 if correct_form_str != ele:\n",
    "#                     any_str_plus = ''.join(p+\"/ANY+\" for p in ele.split(\" \"))[:-1]\n",
    "#                     any_str_space = any_str_plus.replace(\"+\", \" \")\n",
    "#                     config_str = \"KEY\" + any_str_plus + \"->[\" + any_str_space + \"]MERGE[\" + correct_form + \"]\"\n",
    "#                     g = ad_a.write(config_str + \"\\n\")\n",
    "#         elif '/d' in correct_form.split(\" \")[0] and '/p' in correct_form.split(\" \")[0]:\n",
    "#             g = ad_p.write(\"// \" + item + \"\\n\")\n",
    "#             ad_p_count += 1\n",
    "#             all_segs = set()\n",
    "#             for k in i_cons:\n",
    "#                 all_segs.add(k)\n",
    "#             for k in s_cons:\n",
    "#                 all_segs.add(k)\n",
    "#             for ele in all_segs:\n",
    "#                 if correct_form_str != ele:\n",
    "#                     any_str_plus = ''.join(p+\"/ANY+\" for p in ele.split(\" \"))[:-1]\n",
    "#                     any_str_space = any_str_plus.replace(\"+\", \" \")\n",
    "#                     config_str = \"KEY\" + any_str_plus + \"->[\" + any_str_space + \"]MERGE[\" + correct_form + \"]\"\n",
    "#                     g = ad_p.write(config_str + \"\\n\")\n",
    "#         else:\n",
    "#             en_dict[item] = big_dict[item]\n",
    "    \n",
    "    \n",
    "#     else：\n",
    "#         en_dict[item] = big_dict[item]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "g = co.write(str(co_dict))  \n",
    "g = en.write(str(en_dict))\n",
    "    \n",
    "nd.close()\n",
    "wd.close()\n",
    "co.close()\n",
    "cciu.close()\n",
    "ccip.close()\n",
    "ccif.close()\n",
    "cciy.close()\n",
    "ccim.close()\n",
    "ccsu.close()\n",
    "ccsp.close()\n",
    "ccsf.close()\n",
    "ccsy.close()\n",
    "ccsm.close()\n",
    "rn.close()\n",
    "ad_v.close()\n",
    "ad_a.close()\n",
    "ad_p.close()\n",
    "en.close()\n",
    "\n",
    "print(\"nd_count: \" + str(nd_count))\n",
    "print(\"wd_count: \" + str(wd_count))\n",
    "print(\"co_count: \" + str(co_count))\n",
    "\n",
    "print(\"cciu_count: \" + str(cciu_count))\n",
    "print(\"ccip_count: \" + str(ccip_count))\n",
    "print(\"ccif_count: \" + str(ccif_count))\n",
    "print(\"cciy_count: \" + str(cciy_count))\n",
    "print(\"ccim_count: \" + str(ccim_count))\n",
    "print(\"ccsu_count: \" + str(ccsu_count))\n",
    "print(\"ccsp_count: \" + str(ccsp_count))\n",
    "print(\"ccsf_count: \" + str(ccsf_count))\n",
    "print(\"ccsy_count: \" + str(ccsy_count))\n",
    "print(\"ccsm_count: \" + str(ccsm_count))\n",
    "\n",
    "print(\"rn: \" + str(rn_count))\n",
    "print(\"ad_v: \" + str(ad_v_count))\n",
    "print(\"ad_a: \" + str(ad_a_count))\n",
    "print(\"ad_p: \" + str(ad_p_count))\n",
    "print(\"en: \" + str(en_count))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nd_count: 683\n",
    "* wd_count: 3559\n",
    "* co_count: 10119\n",
    "* cciu_count: 170\n",
    "* ccip_count: 223\n",
    "* ccif_count: 273\n",
    "* cciy_count: 17\n",
    "* ccim_count: 134\n",
    "* ccsu_count: 12\n",
    "* ccsp_count: 2\n",
    "* ccsf_count: 8\n",
    "* ccsy_count: 0\n",
    "* ccsm_count: 80\n",
    "* rn: 0\n",
    "* ad_v: 0\n",
    "* ad_a: 0\n",
    "* ad_p: 0\n",
    "* en: 0\n",
    "\n",
    "## need_discuss_confident 已经差不多解决\n",
    "## need_discuss_conflict 是有歧义的分词形况中还没有解决的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中华百家姓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = open(\"config_lastname.txt\", 'w', encoding=\"utf-8-sig\")\n",
    "with open(\"中华百家姓.txt\", encoding=\"utf-8-sig\") as n:\n",
    "    for line in n:\n",
    "        line = line[:-1]\n",
    "        if len(line) == 1:\n",
    "            g = ln.write(\"KEY\" + line + \"某/ANY->[\"+line+\"某/ANY]MERGE[\"+line + \"/nr 某/r]\\n\")\n",
    "            g = ln.write(\"KEY小\" + line + \"/ANY->[小\"+line+\"/ANY]MERGE[小/a \"+line + \"/nr]\\n\")\n",
    "            g = ln.write(\"KEY老\" + line + \"/ANY->[老\"+line+\"/ANY]MERGE[老/a \"+line + \"/nr]\\n\")\n",
    "            g = ln.write(\"\\n\")\n",
    "ln.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中华百家姓的config中会有些本身有意义的词 如 \"老马, 老师, 小云\"等等，人工将其剔除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
